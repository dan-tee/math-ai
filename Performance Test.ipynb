{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb36e15-e88c-475c-915e-f82609610bf7",
   "metadata": {},
   "source": [
    "# Performance Test - Deep Seek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "681bc6fa-9425-445f-91b9-eb49b9363ce5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import re, sys, subprocess, gc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoConfig, GenerationConfig, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-math-7b-rl\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "gen_config = GenerationConfig.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "torch_dtype = torch.bfloat16\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3e970f-2f6f-49c7-8ae0-979fac393c6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_cuda_memory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m     available_memory \u001b[38;5;241m=\u001b[39m total_memory \u001b[38;5;241m-\u001b[39m cached_memory \n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable Memory (GB, approx.): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_memory\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m print_cuda_memory()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'print_cuda_memory' is not defined"
     ]
    }
   ],
   "source": [
    "import sys, gc\n",
    "import torch\n",
    "\n",
    "def free_mem():\n",
    "    if hasattr(sys, 'last_traceback'):\n",
    "        sys.last_traceback.tb_next = None\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "free_mem()\n",
    "\n",
    "def print_cuda_mem():\n",
    "    total_memory = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)\n",
    "    cached_memory = torch.cuda.memory_reserved(0) / (1024 ** 3)\n",
    "    available_memory = total_memory - cached_memory \n",
    "    print(f\"Available Memory (GB, approx.): {available_memory:.2f}\")\n",
    "print_cuda_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a8939-66d9-4615-8313-5a3abbcc0799",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             torch_dtype=torch_dtype,\n",
    "                                             attn_implementation=\"flash_attention_2\",\n",
    "                                             # quantization_config=quantization_config,\n",
    "                                             device_map=\"auto\")\n",
    "print_cuda_memory()\n",
    "print(model.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0009c44-729f-445f-a662-0d77db73ef7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = pd.read_csv('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad4e24e-d373-4610-a2a0-718a4d494860",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_length=125\n",
      "len(raw_output[i][input_length:])=1675\n",
      "len(raw_output[i][input_length:])=1675\n",
      "len(raw_output[i][input_length:])=1675\n",
      "len(raw_output[i][input_length:])=1675\n",
      "64.92562174797058\n"
     ]
    }
   ],
   "source": [
    "tokenizer_max_length = 512\n",
    "max_length = 1800\n",
    "\n",
    "\n",
    "tool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\n",
    "tool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n",
    "\n",
    "messages = [{\n",
    "   \"role\": \"user\", \n",
    "   \"content\": questions.iloc[0]['problem'] + tool_instruction\n",
    "}]\n",
    "query_prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False\n",
    ")\n",
    "start_time = time.time()\n",
    "tokenized = tokenizer(query_prompt, \n",
    "                      return_tensors=\"pt\",\n",
    "                      truncation=True,\n",
    "                      max_length=tokenizer_max_length)\n",
    "input_length = len(tokenized['input_ids'][0])\n",
    "print(f'{input_length=}')\n",
    "tokenized = {key: value.to('cuda') for key, value in tokenized.items()}\n",
    "raw_output = model.generate(**tokenized, \n",
    "                            max_length=max_length,\n",
    "                            do_sample=True,\n",
    "                            temperature=0.9,\n",
    "                            num_return_sequences=4,\n",
    "                            generation_config=gen_config)\n",
    "out_list = []\n",
    "for i in range(len(raw_output)):\n",
    "    print(f'{len(raw_output[i][input_length:])=}')\n",
    "    out_list.append(tokenizer.decode(raw_output[i][input_length:], skip_special_tokens=True))\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6cf9e7-2a74-407e-97cf-41a9ef61a64b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d3736ac-30d4-47da-9bfa-f343ec0a78b6",
   "metadata": {},
   "source": [
    "### Test Results\n",
    "| n Input tokens | n Output tokens  | dtype  | quantization | double quant | flash-atn-2 | eyeball quality | batch size | time | token/s | \n",
    "|----------------|------------------|--------|--------------|--------------|-------------|-----------------|------------|------|---------|\n",
    "| 125            | 1075             |bfloat16| 4-bit        | yes          | yes         | good            | 8          | 99   | 204     |\n",
    "| 125            | 1075             |bfloat16| 4-bit        | yes          | no          | good            | 8          | 99   | 129     |\n",
    "| 125            | 1475             |bfloat16| 4-bit        | yes          | yes         | good            | 4          | 52   | 113     |\n",
    "| 125            | 1155             |bfloat16| 4-bit        | yes          | no          | good            | 1          | 36   | 32      |\n",
    "| 125            | 1155             |bfloat16| 4-bit        | no           | no          | good            | 1          | 36   | 39      |\n",
    "| 125            | 1155             |bfloat16| 8-bit        | yes          | no          | good            | 1          | 102  | 11      |\n",
    "| 125            | 1155             |bfloat16| 8-bit        | no           | no          | good            | 1          | 102  | 11      |\n",
    "| 125            | OOM              |bfloat16| no           | no           | no          | good            | 8          | OOM  | OOM     |\n",
    "| 125            | 1475             |bfloat16| no           | no           | no          | good            | 4          | 53   | 111     |\n",
    "| 125            | 1475             |bfloat16| no           | no           | no          | good            | 2          | 48   | 61      |\n",
    "| 125            | 1155             |bfloat16| no           | no           | no          | good            | 1          | 36   | 32      |\n",
    "| 125            | 908              | float16| no           | no           | no          | good            | 1          | 446  | 2       |\n",
    "| 125            | 552              | float32| no           | no           |  no         |good             | 1          |      |         |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d785fcd-145f-4ce5-84c5-15002332d0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from outlines import models, generate, samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "086599e0-2309-4373-9c64-0235a38f6b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'samplers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sampler \u001b[38;5;241m=\u001b[39m samplers\u001b[38;5;241m.\u001b[39mmultinomial(samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m outlines_model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mTransformers(model, tokenizer)\n\u001b[1;32m      3\u001b[0m generator \u001b[38;5;241m=\u001b[39m generate\u001b[38;5;241m.\u001b[39mtext(outlines_model, sampler)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'samplers' is not defined"
     ]
    }
   ],
   "source": [
    "sampler = samplers.multinomial(samples=1, temperature=0.9, top_k=10)\n",
    "outlines_model = models.Transformers(model, tokenizer)\n",
    "generator = generate.text(outlines_model, sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc7e3619-5ac9-4336-9dbd-f28b1da64174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\n",
    "tool_instruction += '\\nPlease integrate natural language reasoning with programs to solve the problem above, and put your final answer within \\\\boxed{}.'\n",
    "\n",
    "messages = [{\n",
    "   \"role\": \"user\", \n",
    "   \"content\": questions.iloc[0]['problem'] + tool_instruction\n",
    "}]\n",
    "query_prompt = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24f75f33-1bbb-4123-8a21-0659491648ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens=483\n",
      "n_tokens=460\n",
      "n_tokens=407\n",
      "n_tokens=442\n",
      "Ran for 34s at 53.1 token/s.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "answers = generator([query_prompt] * 4, max_tokens=1600)\n",
    "token_counts = []\n",
    "for i in range(len(answers)):\n",
    "    n_tokens = len(tokenizer(answers[i])['input_ids'])\n",
    "    token_counts.append(n_tokens)\n",
    "    print(f\"{n_tokens=}\")\n",
    "    \n",
    "print(f'Ran for {round(time.time() - start_time)}s at {round(sum(token_counts)/(time.time() - start_time), 1)} token/s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fc612-6946-41f9-a9e3-4795a1a7edab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "360e244e-3c63-4c74-86c2-f90e373b8bc7",
   "metadata": {},
   "source": [
    "### Using samples=4\n",
    "n_tokens=494\n",
    "n_tokens=908\n",
    "n_tokens=1601\n",
    "n_tokens=352\n",
    "Ran for 99s at 33.8 token/s.\n",
    "n_tokens=652\n",
    "n_tokens=417\n",
    "n_tokens=538\n",
    "n_tokens=572\n",
    "Ran for 44s at 49.8 token/s.\n",
    "\n",
    "### Using ptompt *4 \n",
    "n_tokens=678\n",
    "n_tokens=380\n",
    "n_tokens=466\n",
    "n_tokens=539\n",
    "Ran for 44s at 47.3 token/s.\n",
    "n_tokens=483\n",
    "n_tokens=460\n",
    "n_tokens=407\n",
    "n_tokens=442\n",
    "Ran for 34s at 53.1 token/s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6128d-b98e-47bb-80e1-ce9d645d5fb9",
   "metadata": {},
   "source": [
    "## vLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5afb9fd1-d1a7-400e-bb39-e76aa73255d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a470aed-3b63-4564-9c82-979a08830314",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Memory (GB, approx.): 23.64\n"
     ]
    }
   ],
   "source": [
    "free_mem()\n",
    "print_cuda_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dd27dee-07e9-48fd-8bf0-8b264c509890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 04-23 15:20:18 config.py:767] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-23 15:20:18 config.py:381] Using fp8_e5m2 data type to store kv cache. It reduces the GPU memory footprint and boosts the performance. But it may cause slight accuracy drop. Currently we only support fp8 without scaling factors and make e5m2 as a default format.\n",
      "INFO 04-23 15:20:18 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='deepseek-ai/deepseek-math-7b-rl', tokenizer='deepseek-ai/deepseek-math-7b-rl', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=True, quantization=None, enforce_eager=True, kv_cache_dtype=fp8_e5m2, device_config=cuda, seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-23 15:20:19 selector.py:51] Cannot use FlashAttention because the package is not found. Please install it for better performance.\n",
      "INFO 04-23 15:20:19 selector.py:25] Using XFormers backend.\n",
      "INFO 04-23 15:20:20 weight_utils.py:177] Using model weights format ['*.safetensors']\n",
      "INFO 04-23 15:20:23 model_runner.py:104] Loading model weights took 12.8725 GB\n",
      "INFO 04-23 15:20:24 gpu_executor.py:94] # GPU blocks: 2569, # CPU blocks: 1092\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "vllm = LLM(model=model_name,\n",
    "          dtype='half',\n",
    "          enforce_eager=True,\n",
    "          gpu_memory_utilization=0.99,\n",
    "          swap_space=4,\n",
    "          max_model_len=2048,\n",
    "          kv_cache_dtype=\"fp8_e5m2\",\n",
    "          tensor_parallel_size=1)\n",
    "vtokenizer = vllm.get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42406eb4-ea52-44ff-b69f-826f680c12ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 1/1 [00:24<00:00, 24.73s/it]\n"
     ]
    }
   ],
   "source": [
    "tool_sampling_params = SamplingParams(n=8,\n",
    "                                      temperature=0.9,\n",
    "                                      max_tokens=2048,\n",
    "                                      stop='output')\n",
    "llm_out = vllm.generate(query_prompt, tool_sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24cc7343-1966-4712-9ccb-54e31504d33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionOutput(index=0, text='```python\\nfrom sympy import symbols, solve, sqrt\\n\\ndef sum_of_squares_distances():\\n    \"\"\"Let $k, l > 0$ be parameters. The parabola $y = kx^2 - 2kx + l$ intersects the line $y = 4$ at two points $A$ and $B$. These points are distance 6 apart. What is the sum of the squares of the distances from $A$ and $B$ to the origin? The answer should be given as a non-negative modulo 1000.\"\"\"\\n    # Symbols\\n    k, l, x = symbols(\\'k l x\\')\\n\\n    # Equation of the parabola\\n    parabola = k*x**2 - 2*k*x + l - 4\\n\\n    # Equation for the distance between A and B\\n    distance = sqrt((x[1] - x[0])**2 + (4 - 4)**2) - 6\\n\\n    # Solve the system of equations\\n    solutions = solve([parabola, distance], (k, l, x))\\n\\n    # Calculate the sum of the squares of the distances from A and B to the origin\\n    sum_of_squares = sum([sqrt(x[0]**2 + 4**2)**2 + sqrt(x[1]**2 + 4**2)**2 for x in solutions])\\n\\n    # Return the sum modulo 1000\\n    return sum_of_squares % 1000\\n\\nresult = sum_of_squares_distances()\\nprint(result)\\n```\\n```', token_ids=[10897, 11338, 185, 3163, 4300, 4027, 1666, 17044, 11, 8708, 11, 83130, 185, 185, 1558, 2555, 62, 994, 62, 72582, 62, 5983, 2271, 10935, 185, 300, 8066, 4160, 363, 74, 11, 284, 1879, 207, 15, 3, 330, 4823, 13, 429, 90350, 4499, 363, 88, 403, 530, 87, 61, 17, 570, 207, 17, 83265, 919, 284, 3, 63977, 254, 1353, 363, 88, 403, 207, 19, 3, 430, 984, 3487, 363, 32, 3, 285, 363, 33, 1332, 3410, 3487, 418, 5013, 207, 21, 8146, 13, 2461, 317, 254, 2555, 280, 254, 26532, 280, 254, 20421, 473, 363, 32, 3, 285, 363, 33, 3, 276, 254, 6947, 30, 429, 3510, 1023, 330, 2028, 372, 245, 2170, 12, 20805, 40481, 207, 16, 15, 15, 15, 27823, 185, 300, 1501, 30309, 82, 185, 300, 530, 11, 284, 11, 1376, 403, 17044, 1504, 74, 284, 1376, 2519, 185, 185, 300, 1501, 27892, 280, 254, 90350, 4499, 185, 300, 90350, 4499, 403, 530, 9, 87, 746, 17, 570, 207, 17, 9, 74, 9, 87, 919, 284, 570, 207, 19, 185, 185, 300, 1501, 27892, 327, 254, 5013, 1439, 338, 285, 380, 185, 300, 5013, 403, 83130, 6034, 87, 58, 16, 60, 570, 1376, 58, 15, 5855, 746, 17, 919, 334, 19, 570, 207, 19, 8, 746, 17, 8, 570, 207, 21, 185, 185, 300, 1501, 6121, 313, 254, 1317, 280, 8935, 185, 300, 5566, 403, 8708, 9244, 1060, 356, 4499, 11, 5013, 2717, 334, 74, 11, 284, 11, 1376, 1509, 185, 185, 300, 1501, 50586, 254, 2555, 280, 254, 26532, 280, 254, 20421, 473, 338, 285, 380, 276, 254, 6947, 185, 300, 2555, 62, 994, 62, 72582, 403, 2555, 9244, 4221, 7, 87, 58, 15, 60, 746, 17, 919, 207, 19, 746, 17, 8, 746, 17, 919, 83130, 7, 87, 58, 16, 60, 746, 17, 919, 207, 19, 746, 17, 8, 746, 17, 327, 1376, 279, 5566, 5855, 185, 185, 300, 1501, 7898, 254, 2555, 40481, 207, 16, 15, 15, 15, 185, 300, 972, 2555, 62, 994, 62, 72582, 3028, 207, 16, 15, 15, 15, 185, 185, 4260, 403, 2555, 62, 994, 62, 72582, 62, 5983, 2271, 826, 185, 4134, 7, 4260, 8, 185, 10897, 185, 10897, 8157], cumulative_logprob=-25.98331305882192, logprobs=None, finish_reason=stop, stop_reason=output)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_out[0].outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a0762263-34e4-4763-ba2d-992f01568d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0: The graph of the equation $9x+223y=2007$ is drawn on graph paper with each square representing one unit in each direction. How many of the $1$ by $1$ graph paper squares have interiors lying entirely below the graph and entirely in the first quadrant?\n",
      "\n",
      "18:19:20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='Traceback (most recent call last):\\n  File \"/home/daniel/code/math-ai/code.py\", line 21, in <module>\\n    result = count_squares()\\n             ^^^^^^^^^^^^^^^\\n  File \"/home/daniel/code/math-ai/code.py\", line 11, in count_squares\\n    y_intercept = solve(x, y)[0].evalf()\\n                  ~~~~~~~~~~~^^^\\nIndexError: list index out of range\\n'\n",
      "\n",
      "18:19:54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='888\\n'\n",
      "\n",
      "18:20:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='0\\n'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second_output=[{'generated_text': '```python\\ndef graph_paper_squares():\\n    \"\"\"The graph of the equation $9x+223y=2007$ is drawn on graph paper with each square representing one unit in each direction. How many of the $1$ by $1$ graph paper squares have interiors lying entirely below the graph and entirely in the first quadrant?\\n\"\"\"\\n    # Define the variables\\n    x, y = symbols(\\'x y\\', real=True)\\n    \\n    # Solve the equation for y\\n    y_expr = solve(9*x + 223*y - 2007, y)[0]\\n\\n    # Find the integer values of x for which y is a positive integer\\n    count = 0\\n    for i in range(1, 2017):\\n        if i % 9 == 0:\\n            x_val = i / 9\\n            y_val = y_expr.subs(x, x_val)\\n            if y_val.is_positive and y_val == int(y_val):\\n                count += 1\\n\\n    return count\\n\\nnumber_of_squares = graph_paper_squares()\\nprint(number_of_squares)\\n```\\n```output\\n0\\n```\\nThe number of 1 by 1 graph paper squares that have interiors lying entirely below the graph and entirely in the first quadrant is 0. This is because the graph of the equation $9x+223y=2007$ does not intersect the first quadrant. The graph is a straight line with a negative slope, and it passes through the point $(-2007/9, 0)$, which is in the third quadrant. Therefore, there are no squares in the first quadrant that lie entirely below the graph.'}]\n",
      "\n",
      "\n",
      "\n",
      "1: Let $\\mathcal{P}$ be the parabola in the plane determined by the equation $y = x^2.$  Suppose a circle $\\mathcal{C}$ intersects $\\mathcal{P}$ at four distinct points.  If three of these points are $(-28,784),$ $(-2,4),$ and $(13,169),$ find the sum of the distances from the focus of $\\mathcal{P}$ to all four of the intersection points.\n",
      "18:20:28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='2*sqrt(5) + 13*sqrt(170) + 28*sqrt(785)\\n'\n",
      "\n",
      "18:21:03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='  File \"/home/daniel/code/math-ai/code.py\", line 2\\n    Find the distance of the four points to the focus of the parabola y = x^2.\\n         ^^^\\nSyntaxError: invalid syntax\\n'\n",
      "\n",
      "18:21:17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/logging/__init__.py\", line 1110, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/logging/__init__.py\", line 953, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/logging/__init__.py\", line 687, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/logging/__init__.py\", line 377, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_10218/895227761.py\", line 53, in <module>\n",
      "    second_output = pipeline(second_prompt, max_new_tokens=1024, do_sample=True, temperature=0.1, return_full_text=False)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/transformers/pipelines/text_generation.py\", line 240, in __call__\n",
      "    return super().__call__(text_inputs, **kwargs)\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/transformers/pipelines/base.py\", line 1167, in __call__\n",
      "    logger.warning_once(\n",
      "  File \"/home/daniel/mambaforge/envs/pytorch/lib/python3.11/site-packages/transformers/utils/logging.py\", line 329, in warning_once\n",
      "    self.warning(*args, **kwargs)\n",
      "Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'\n",
      "Arguments: (<class 'UserWarning'>,)\n",
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shell_output='957.750000000000\\n'\n",
      "\n",
      "second_output=[{'generated_text': '```python\\nfrom sympy import symbols, solve, N\\n\\ndef sum_of_distances_intersection_points():\\n    \"\"\"Problem: Let $\\\\mathcal{P}$ be the parabola in the plane determined by the equation $y = x^2.$  Suppose a circle $\\\\mathcal{C}$ intersects $\\\\mathcal{P}$ at four distinct points.  If three of these points are $(-28,784),$ $(-2,4),$ and $(13,169),$ find the sum of the distances from the focus of $\\\\mathcal{P}$ to all four of the intersection points.\\n\"\"\"\\n    x, y = symbols(\\'x y\\', real=True)\\n\\n    # The focus of the parabola y = x^2 is at (0, 1/4)\\n    focus_x, focus_y = 0, 1/4\\n\\n    # The given intersection points\\n    points = [(-28, 784), (-2, 4), (13, 169)]\\n\\n    # The sum of the distances from the focus to the intersection points\\n    sum_of_distances = 0\\n    for point in points:\\n        # Calculate the distance using the distance formula\\n        sum_of_distances += ((focus_x - point[0])**2 + (focus_y - point[1])**2)**0.5\\n\\n    # Convert the sum of distances to decimal\\n    sum_of_distances = N(sum_of_distances)\\n\\n    return sum_of_distances\\n\\nresult = sum_of_distances_intersection_points()\\nprint(result)\\n```\\n```output\\n957.750000000000\\n\\n```\\nThe sum of the distances from the focus of the parabola $y = x^2$ to all four of the intersection points is approximately $957.75$.'}]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tool_instruction = \" The answer should be given as a non-negative modulo 1000.\"\n",
    "\n",
    "n_repetitions = 3\n",
    "q_ics = []\n",
    "raw_results = []\n",
    "total_results = []\n",
    "total_answers = []\n",
    "\n",
    "for q_idx in range(len(questions)):\n",
    "    print(f\"\\n\\n{q_idx}: {questions['problem'].iloc[q_idx]}\")\n",
    "    results = []\n",
    "    answers = []\n",
    "    try:\n",
    "        combined_messages = None\n",
    "        for rep_idx in range(n_repetitions):\n",
    "            print(datetime.now().strftime('%H:%M:%S'))\n",
    "            if rep_idx > (n_repetitions + 1) / 2:\n",
    "                problem = clean_latex(questions['problem'].iloc[q_idx])\n",
    "            else:\n",
    "                problem = questions['problem'].iloc[q_idx] \n",
    "            messages = [{\n",
    "                \"role\": \"user\", \n",
    "                \"content\": 'Problem: ' + problem + \"\\nGenerate Python code to solve the above problem.\" +\n",
    "                '\\nUnless complex numbers are mentioned in the problem create SymPy symbols with parameter real=True' +\n",
    "                    '\\n```python\\n'\n",
    "            }]\n",
    "            query_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "            first_output = pipeline(query_prompt, max_new_tokens=1024, do_sample=True, temperature=0.9, return_full_text=False)\n",
    "            first_output = '```python\\n' + first_output[0]['generated_text']\n",
    "            # print('Shell input: \\n' + first_output.split('```')[1][7:] + '\\n')\n",
    "            shell_output = run_python_code(first_output.split('```')[1][7:])\n",
    "            print(f'{shell_output=}\\n')\n",
    "            with_output = first_output.split('```output')[0] + f'```output\\n{shell_output}\\n```'\n",
    "            message = {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f'Answer {rep_idx}:\\n```python\\n' + with_output\n",
    "            }\n",
    "            messages.append(message)\n",
    "            #torch.cuda.empty_cache()\n",
    "            #gc.collect()\n",
    "            if combined_messages is None:\n",
    "                combined_messages = messages\n",
    "            else: \n",
    "                combined_messages.append(message)\n",
    "                \n",
    "        combined_messages.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"\"\n",
    "                    \n",
    "        })\n",
    "        second_prompt = tokenizer.apply_chat_template(combined_messages, tokenize=False).replace('<｜end▁of▁sentence｜>', '')\n",
    "        # print(f'{second_prompt=}\\n')\n",
    "        second_output = pipeline(second_prompt, max_new_tokens=1024, do_sample=True, temperature=0.1, return_full_text=False)\n",
    "        print(f'{second_output=}\\n')\n",
    "        \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        result_output, code_output = -1, -1 \n",
    "    raw_results.append(second_output)\n",
    "    result_output, code_output = process_output(second_output)\n",
    "\n",
    "\n",
    "    results.append(result_output)\n",
    "    answers.append(code_output)\n",
    "    q_ics.append(q_idx)\n",
    "total_results.append(results)\n",
    "total_answers.append(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e6bff0-99c2-4593-9b35-7513ff8a4dba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3*c + 2*cp\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, solve, Eq\n",
    "def solve_triangle():\n",
    "    # Define the variables\n",
    "    a, b, c, pa, cp = symbols('a b c pa cp')\n",
    "    # From the angle bisector theorem, we have: a/b = (c+a)/(2c)\n",
    "    # Simplify this to get the ratio of a to b\\n \n",
    "    ratio = solve(Eq(a/b, (c+a)/(2*c)), a/b)[0]\n",
    "    # Given that M is the midpoint of AD, we have: pa = 2*cp\n",
    "    # Substitute this into the ratio to get the ratio of cp to pa\n",
    "    ratio = ratio.subs(a, 2*cp)\n",
    "    # Simplify the ratio\n",
    "    ratio = ratio.simplify()\n",
    "    # The problem asks for the sum of m and n in the fraction m,\n",
    "    # where m and n are relatively prime positive integers.\n",
    "    # The ratio we found is in the form m/n. So, m = cp and n = pa.\n",
    "    m, n = ratio.as_numer_denom()\n",
    "    # Calculate m+n\\n \n",
    "    sum_mn = m + n\n",
    "    return sum_mn\n",
    "result = solve_triangle()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e6b42a-a1e8-4980-accb-6ce884072c20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame({\n",
    "#     'question': np.repeat(questions.values, n_repetitions),\n",
    "#     'sympy_answers': total_answers,\n",
    "#     'llm_answers': total_results,\n",
    "#     'raw_answers': raw_results\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb37899c-65b2-44be-8b20-e3b817fb4166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n",
      "25\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(np.repeat(questions['problem'].values, n_repetitions)))\n",
    "print(len(raw_results))\n",
    "print(len(total_results))\n",
    "print(len(total_answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8d610e8-14ba-402a-8237-1539f65c124c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When the expression $4(x^2-2x+2)-7(x^3-3x+1)$ is fully simplified, what is the sum of the squares of the coefficients of the terms?'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['problem'].iloc[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c6668a-612f-47b6-afe4-220122c4d961",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, -1, -1], [-1, 2, -1], [-1, 1, 1]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc2c791-8845-4c45-88df-3bb8167033dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-1, 995, 995], [2, 2, -1], [-1, 2, 2]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "600d7f21-55a1-4795-9358-b654d9c40156",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In general, $\\\\mathbf{M} \\\\begin{pmatrix} 1 \\\\\\\\ 0 \\\\end{pmatrix}$ is the first column of $\\\\mathbf{M}$, and $\\\\mathbf{M} \\\\begin{pmatrix} 0 \\\\\\\\ 1 \\\\end{pmatrix}$ is the second column of $\\\\mathbf{M}.$\\n\\nTaking $\\\\mathbf{v} = \\\\begin{pmatrix} 1 \\\\\\\\ 0 \\\\end{pmatrix},$ we get\\n\\\\[-5 \\\\begin{pmatrix} 1 \\\\\\\\ 0 \\\\end{pmatrix} = \\\\begin{pmatrix} -5 \\\\\\\\ 0 \\\\end{pmatrix}.\\\\]Taking $\\\\mathbf{v} = \\\\begin{pmatrix} 0 \\\\\\\\ 1 \\\\end{pmatrix},$ we get\\n\\\\[-5 \\\\begin{pmatrix} 0 \\\\\\\\ 1 \\\\end{pmatrix} = \\\\begin{pmatrix} 0 \\\\\\\\ -5 \\\\end{pmatrix}.\\\\]Therefore,\\n\\\\[\\\\mathbf{M} = \\\\boxed{\\\\begin{pmatrix} -5 & 0 \\\\\\\\ 0 & -5 \\\\end{pmatrix}}.\\\\]',\n",
       "       'We have that\\n\\\\begin{align*}\\nak^3 + bk^2 + ck + d &= 0, \\\\\\\\\\nbk^3 + ck^2 + dk + a &= 0.\\n\\\\end{align*}Multiplying the first equation by $k,$ we get\\n\\\\[ak^4 + bk^3 + ck^2 + dk = 0.\\\\]Subtracting the equation $bk^3 + ck^2 + dk + a = 0,$ we get $ak^4 = a.$  Since $a$ is nonzero, $k^4 = 1.$  Then $k^4 - 1 = 0,$ which factors as\\n\\\\[(k - 1)(k + 1)(k^2 + 1) = 0.\\\\]This means $k$ is one of $1,$ $-1,$ $i,$ or $-i.$\\n\\nIf $a = b = c = d = 1,$ then $-1,$ $i,$ and $-i$ are roots of both polynomials.  If $a = b = c = 1$ and $d = -3,$ then 1 is a root of both polynomials.  Therefore, the possible values of $k$ are $\\\\boxed{1,-1,i,-i}.$',\n",
       "       'Let $y = 3^x.$  Then\\n\\\\[9^x - 3^x + 1 = y^2 - y + 1 = \\\\left( y - \\\\frac{1}{2} \\\\right)^2 + \\\\frac{3}{4}.\\\\]Thus, the minimum value is $\\\\boxed{\\\\frac{3}{4}},$ which occurs when $y = \\\\frac{1}{2},$ or $x = \\\\log_3 \\\\frac{1}{2}.$'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions['solution'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f70ce962-d383-41b0-90fb-82c401506500",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "propm_prefix = '''Problem:\n",
    "Find the domain of the expression $\\frac{\\sqrt{x-2}}{\\sqrt{5-x}}$.}\n",
    "\n",
    "Solution:\n",
    "The expressions inside each square root must be non-negative. Therefore,\n",
    "$x-2 \\ge 0$, so $x\\ge2$, and $5 - x \\ge 0$, so $x \\le 5$. Also, the denominator\n",
    "cannot be equal to zero, so $5-x>0$, which gives $x<5$. Therefore, the domain of\n",
    "the expression is $\\boxed{[2,5)}$.\n",
    "Final Answer: The final answer is $[2,5)$. I hope it is correct.\n",
    "\n",
    "Problem:\n",
    "If $\\det \\mathbf{A} = 2$ and $\\det \\mathbf{B} = 12,$ then find\n",
    "$\\det (\\mathbf{A} \\mathbf{B}).$\n",
    "Solution:\n",
    "We have that $\\det (\\mathbf{A} \\mathbf{B}) = (\\det \\mathbf{A})(\\det \\mathbf{B})\n",
    "= (2)(12) = \\boxed{24}.$\n",
    "Final Answer: The final answer is $24$. I hope it is correct.\n",
    "Problem:\n",
    "Terrell usually lifts two 20-pound weights 12 times. If he uses two 15-pound\n",
    "weights instead, how many times must Terrell lift them in order to lift the\n",
    "same total weight?\n",
    "\n",
    "Solution:\n",
    "If Terrell lifts two 20-pound weights 12 times, he lifts a total of\n",
    "$2\\cdot 12\\cdot20=480$ pounds of weight. If he lifts two 15-pound\n",
    "weights instead for $n$ times, he will lift a total of $2\\cdot15\\cdot n=30n$\n",
    "pounds of weight. Equating this to 480 pounds, we can solve for $n$:\n",
    "\\begin{align*}\n",
    "30n&=480\\\\\n",
    "\\Rightarrow\\qquad n&=480/30=\\boxed{16}\n",
    "\\end{align*}\n",
    "Final Answer: The final answer is $16$. I hope it is correct.\n",
    "\n",
    "Problem:\n",
    "If the system of equations\n",
    "\\begin{align*}\n",
    "6x-4y&=a,\\\\\n",
    "6y-9x &=b.\n",
    "\\end{align*}has a solution $(x, y)$ where $x$ and $y$ are both nonzero,\n",
    "find $\\frac{a}{b},$ assuming $b$ is nonzero.\n",
    "\n",
    "Solution:\n",
    "If we multiply the first equation by $-\\frac{3}{2}$, we obtain\n",
    "$$6y-9x=-\\frac{3}{2}a.$$Since we also know that $6y-9x=b$, we have\n",
    "$$-\\frac{3}{2}a=b\\Rightarrow\\frac{a}{b}=\\boxed{-\\frac{2}{3}}.$$\n",
    "Final Answer: The final answer is $-\\frac{2}{3}$. I hope it is correct.\n",
    "\n",
    "Problem:\n",
    "'''\n",
    "\n",
    "question_easy = 'Beth bakes 4, 2 dozen batches of cokies in a week. If these cookies are shared amongst 16 people equally, how many cookies does each person consume?'\n",
    "question_hard = 'Each of the three-digits numbers $111$ to $999$ is coloured blue or yellow in such a way that the sum of any two (not necessarily different) yellow numbers is equal to a blue number. What is the maximum possible number of yellow numbers there can be?'\n",
    "postfix = '\\nPlease reason step by step, and put your final answer within \\boxed{}.'\n",
    "postfix_2 =  '\\nPlease convert this problem into a set of equations'\n",
    "tokens = tokenizer.encode(question_hard + postfix_2, return_tensors='pt').to('cuda')\n",
    "out_tokens = model.generate(tokens, max_length=500)\n",
    "print(tokenizer.decode(out_tokens[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae0d586f-0b4e-4f4a-9f48-b5ebf178f029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'subs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m         d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     25\u001b[0m         e \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 27\u001b[0m solve_for_prob()\n",
      "Cell \u001b[0;32mIn[34], line 14\u001b[0m, in \u001b[0;36msolve_for_prob\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m valid_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m    \n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m16\u001b[39m):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m condition\u001b[38;5;241m.\u001b[39msubs(x, i): \n\u001b[1;32m     15\u001b[0m         valid_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# calculate the total number of values of x in the interval\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'subs'"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Rational, floor, sqrt\n",
    "from sympy import solve, And, Le, Ge\n",
    "def solve_for_prob():\n",
    "    x = symbols('x')\n",
    "    # define the polynomial P(x)\n",
    "    P = x**2 - 3*x - 9\n",
    "    # define the condition for the problem\n",
    "    condition = floor(sqrt(P.subs(x, x))) == sqrt(P.subs(x, floor(x)))\n",
    "    # define the interval\n",
    "    interval = And(5 <= x, x <= 15)\n",
    "    # calculate the number of values of x that satisfy the condition in the interval\n",
    "    valid_count = 0    \n",
    "    for i in range(5, 16):\n",
    "        if condition.subs(x, i): \n",
    "            valid_count += 1\n",
    "        # calculate the total number of values of x in the interval\n",
    "        total_count = 15 - 5 + 1\n",
    "        # calculate the probability\n",
    "        probability = Rational(valid_count, total_count)\n",
    "        # calculate a, b, c, d, e for the fraction form of the probability\n",
    "        a = 1\n",
    "        b = 1\n",
    "        c = 1\n",
    "        d = -1\n",
    "        e = 1\n",
    "        \n",
    "solve_for_prob()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a69e4a-c8c1-4d62-92b8-7377d573c94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "˘.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
